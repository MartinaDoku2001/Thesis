{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"dBcCQ4Tu0h6H"},"source":["<h1 style=\"text-align:center; font-size:200%; color:red;\"> <b> PROPOSED MODEL </b> </h1>\n","<div id=\"author\"; style=\"text-align:center; font-size:150%;\" > <b> Martina Doku </b> </div>\n","<div id=\"project\"; style=\"text-align:center; font-size:100%;\" > <b>  Bachelor Thesis in Applied Computer Science And Artificial Intelligence </b> </div>\n","<div id=\"year\"; style=\"text-align:center; font-size:100%;\" > <b>  2023 </b> </div>\n","<div id=\"university\"; style=\"text-align:center; font-size:100%;\" > <b>  University of Rome \"La Sapienza\"</b> </div>\n","<div id=\"supervisor\"; style=\"text-align:center; font-size:100%;\" > <b>  Prof. Danilo Avola </b> </div>\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zo_tR2PU0tew"},"source":["<h2 style=\"text-align:center; font-size:180%; color:red;\"> <b> 1. DATA PREPARATION </b> </h2>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T06:35:47.479400Z","iopub.status.busy":"2023-06-14T06:35:47.478969Z","iopub.status.idle":"2023-06-14T06:35:47.485770Z","shell.execute_reply":"2023-06-14T06:35:47.484554Z","shell.execute_reply.started":"2023-06-14T06:35:47.479353Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683190455844,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"b43f0pMM1FEv","trusted":true},"outputs":[],"source":["#LIBRARIES\n","import numpy as np\n","import os \n","import matplotlib.pyplot as plt\n","import sklearn.model_selection as ms\n","import scipy.io as sio\n","import math\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import pickle\n","import pandas as pd\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T06:35:47.492215Z","iopub.status.busy":"2023-06-14T06:35:47.491463Z","iopub.status.idle":"2023-06-14T06:35:47.501995Z","shell.execute_reply":"2023-06-14T06:35:47.500860Z","shell.execute_reply.started":"2023-06-14T06:35:47.492154Z"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683190455844,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"A5Ga1r8u1xQX","trusted":true},"outputs":[],"source":["#data path\n","data_path = '/kaggle/input/dataset'\n","#results path\n","results_path = '/kaggle/working/'\n","\n","#model name\n","model_name = 'positional_transformer_res_blocks'"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2 style=\" font-size:150%; color:red;\"> <b> 1.2. loading data </b> </h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T06:35:47.504077Z","iopub.status.busy":"2023-06-14T06:35:47.503591Z","iopub.status.idle":"2023-06-14T06:35:49.421043Z","shell.execute_reply":"2023-06-14T06:35:49.420110Z","shell.execute_reply.started":"2023-06-14T06:35:47.504044Z"},"executionInfo":{"elapsed":5508,"status":"ok","timestamp":1683190461347,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"S6DOYORa1yd1","outputId":"8e554bcd-f6fa-4592-9688-c3c4f7006c6f","trusted":true},"outputs":[],"source":["#LOADING DATA \n","\n","pure_EEG=np.load(os.path.join(data_path,'EEG_all_epochs.npy')) #load EEG pure data\n","pure_EMG=np.load(os.path.join(data_path,'EMG_all_epochs.npy')) #load EMG data\n","pure_EOG=np.load(os.path.join(data_path,'EOG_all_epochs.npy')) #load EOG data\n","\n","fig, axs = plt.subplots(3, 5, figsize=(15, 10))\n","for i in range(5):\n","    axs[0,i].set_title('EEG')\n","    axs[0,i].plot(range(len(pure_EEG[i])),pure_EEG[i])\n","\n","    axs[1,i].set_title('EMG')\n","    axs[1,i].plot(range(len(pure_EMG[i])),pure_EMG[i])\n","    \n","    axs[2,i].set_title('EOG')\n","    axs[2,i].plot(range(len(pure_EOG[i])),pure_EOG[i])\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xYoAS5DE2lpA"},"source":["<h2 style=\" font-size:150%; color:red;\"> <b> 1.2 data preprocessing </b> </h2>\n","<div> In this section I will prepare the data to be used in the models.Specifically, we are going to create a dataset composed of:\n","<ol>\n","    <li> <b>EEG_raw_training_data</b>: 80% of the EEG signals </li>\n","    <li> <b>EEG_clean_training_data</b>: 80% of the clean EEG signals </li>\n","    <li> <b>EEG_raw_validation_data</b>: 10% of the EEG signals </li>\n","    <li> <b>EEG_clean_validation_data</b>: 10% of the clean EEG signals </li>\n","    <li> <b>EEG_raw_test_data</b>: 10% of the EEG signals </li>\n","    <li> <b>EEG_clean_test_data</b>: 10% of the clean EEG signals </li>  \n","</ol>\n","</div>\n","<div style=\"color:red\" > <b> Note:</b> </div> <div> The process includes code from the <a href=\"https://github.com/ncclabsustech/EEGdenoiseNet\">EEGdenoiseNet</a> repository. </div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T06:35:49.424367Z","iopub.status.busy":"2023-06-14T06:35:49.423647Z","iopub.status.idle":"2023-06-14T06:35:49.462421Z","shell.execute_reply":"2023-06-14T06:35:49.461356Z","shell.execute_reply.started":"2023-06-14T06:35:49.424330Z"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1683190461347,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"SOGiep7B2Qr_","trusted":true},"outputs":[],"source":["# Author: Haoming Zhang\n","#The code here not only include data importing, but also data standardization and the generation of analog noise signals\n","\n","\n","#PERFORMS THE STANDARD DEVIATION OF THE RECORDS\n","def get_std(records):\n","    return math.sqrt(sum([x ** 2 for x in records]) / len(records)) \n","\n","\n","#AUGMENTS THE SIGNAL AND ADDS RANDOM DISTURB\n","def random_signal(signal,combin_num):   #signal= EEG data (?), combin_num= number of times we want to shuffle data (factor of which)\n","                                        #we want to augment our data\n","    random_result=[]\n","\n","    for i in range(combin_num):\n","        random_num = np.random.permutation(signal.shape[0])     #creates a random shuffled list of integers from 0 to signal.shape[0]\n","        shuffled_dataset = signal[random_num,:]                #takes the elemnt of signal in the order we just shuffled\n","        shuffled_dataset = shuffled_dataset.reshape(signal.shape[0],signal.shape[1]) #reshapes it to have the sam eshap eof the original signal\n","        random_result.append(shuffled_dataset)                  #adds the shuffled signal to final result (we may want to repeat those steps to augment data)\n","    random_result  = np.array(random_result)\n","\n","    return  random_result\n","\n","\n","#OBTAINING RAW DATA (training, validation and test)\n","def prepare_data(EEG_all, noise_all, combin_num, train_per, noise_type):    #EEG_all= original eeg data\n","                                                                            #noise_all= original noise data\n","                                                                            #combin_num= factor of which we wanto to augment data\n","                                                                            #train_per=percentage of data that we want to use as training [0,1]\n","                                                                            #noise_type= 'EMG' or 'EOG'\n","\n","    EEG_all_random = np.squeeze(random_signal(signal = EEG_all, combin_num = 1))        #shuffling pure eeg\n","    noise_all_random = np.squeeze(random_signal(signal = noise_all, combin_num = 1))    #shuffling pure noise\n","\n","    #If the noise type is EMG, EEG signal will be partially reused to match 'EMG signal' shape\n","    if noise_type == 'EMG':                  \n","        reuse_num = noise_all_random.shape[0] - EEG_all_random.shape[0] #we find the differenece of dimensions between EEG and EMG, n\n","        EEG_reuse = EEG_all_random[0 : reuse_num, :]                    #we select aportion of magnitude n from EEG\n","        EEG_all_random = np.vstack([EEG_reuse, EEG_all_random])         #stack original EEG  with that extra portion \n","        print('EEG segments after reuse: ',EEG_all_random.shape[0])\n","\n","    #If the noise type is EOG, EEG signal will be partially dropped to match 'EOG signal' shape\n","    elif noise_type == 'EOG':  \n","        EEG_all_random = EEG_all_random[0:noise_all_random.shape[0]]    #We drop some of the EEG signal to much the number of EMG\n","        print('EEG segments after drop: ',EEG_all_random.shape[0])\n","\n","\n","    #defining important data\n","    timepoint = noise_all_random.shape[1]                               #get the number of timestamps\n","    train_num = round(train_per * EEG_all_random.shape[0])              #the number of training points\n","    validation_num = round((EEG_all_random.shape[0] - train_num) / 2)   #the number of validation points\n","    test_num = EEG_all_random.shape[0] - train_num - validation_num     #the number of test points\n","\n","    #splitting EEG in train,validation,test\n","    train_eeg = EEG_all_random[0 : train_num, :]\n","    validation_eeg = EEG_all_random[train_num : train_num + validation_num, :]\n","    test_eeg = EEG_all_random[train_num + validation_num : EEG_all_random.shape[0], :]\n","\n","    #splittting EEG in train,validation,test\n","    train_noise = noise_all_random[0 : train_num, :]\n","    validation_noise = noise_all_random[train_num : train_num + validation_num,:]\n","    test_noise = noise_all_random[train_num + validation_num : noise_all_random.shape[0], :]\n","\n","    #Augmenting training data and adding noise, with a factor of combin_num\n","    EEG_train = random_signal(signal = train_eeg, combin_num = combin_num).reshape(combin_num * train_eeg.shape[0], timepoint)\n","    NOISE_train = random_signal(signal = train_noise, combin_num = combin_num).reshape(combin_num * train_noise.shape[0], timepoint)\n","\n","    #################################  simulate noise signal of training set  ##############################\n","\n","    #creating random number between -10dB ~ 2dB\n","    SNR_train_dB = np.random.uniform(-7, 2, (EEG_train.shape[0]))   #samples randomly as many point as the ones in training set\n","    print(SNR_train_dB.shape)                                       #from the uniform distribution from -7 to 2\n","    SNR_train = 10 ** (0.1 * (SNR_train_dB))\n","\n","    #combining eeg and noise for training set \n","    noiseEEG_train=[]\n","    NOISE_train_adjust=[]\n","    for i in range (EEG_train.shape[0]):\n","        eeg=EEG_train[i].reshape(EEG_train.shape[1])        #for each sample reates a vector of EEG data\n","        noise=NOISE_train[i].reshape(NOISE_train.shape[1])  #and a vector of noise data\n","\n","        coe=get_std(eeg)/(get_std(noise)*SNR_train[i])      #computes a mixing coefficient as the std of eeg divided by \n","                                                            #the std of noise multiplied by the SNR (random noise?)\n","        noise = noise*coe           #multiply the noise by the coefficient\n","        neeg = noise+eeg            #add it to clean eeg to obtain raw data\n","\n","        NOISE_train_adjust.append(noise)\n","        noiseEEG_train.append(neeg)\n","\n","    noiseEEG_train=np.array(noiseEEG_train)                 #create an array with raw train EEg\n","    NOISE_train_adjust=np.array(NOISE_train_adjust)         #create an array with the noise we added to the pure eeg\n","\n","    #dividing each epoch of training data (both raw and clean) for standard deviation\n","    EEG_train_end_standard = []\n","    noiseEEG_train_end_standard = []\n","\n","    for i in range(noiseEEG_train.shape[0]):\n","        eeg_train_all_std = EEG_train[i] / np.std(noiseEEG_train[i])\n","        EEG_train_end_standard.append(eeg_train_all_std)\n","\n","        noiseeeg_train_end_standard = noiseEEG_train[i] / np.std(noiseEEG_train[i])\n","        noiseEEG_train_end_standard.append(noiseeeg_train_end_standard)\n","\n","    noiseEEG_train_end_standard = np.array(noiseEEG_train_end_standard)\n","    EEG_train_end_standard = np.array(EEG_train_end_standard)\n","    print('training data prepared', noiseEEG_train_end_standard.shape, EEG_train_end_standard.shape )\n","\n","    #################################  simulate noise signal of validation  ##############################\n","\n","    SNR_val_dB = np.linspace(-7.0, 2.0, num=(10))\n","    SNR_val = 10 ** (0.1 * (SNR_val_dB))\n","\n","    eeg_val = np.array(validation_eeg)\n","    noise_val = np.array(validation_noise)\n","    \n","    # combin eeg and noise for test set \n","    EEG_val = []\n","    noise_EEG_val = []\n","    for i in range(10):\n","        \n","        noise_eeg_val = []\n","        for j in range(eeg_val.shape[0]):\n","            eeg = eeg_val[j]\n","            noise = noise_val[j]\n","            \n","            coe = get_std(eeg) / (get_std(noise) * SNR_val[i])\n","            noise = noise * coe\n","            neeg = noise + eeg\n","            \n","            noise_eeg_val.append(neeg)\n","        \n","        EEG_val.extend(eeg_val)\n","        noise_EEG_val.extend(noise_eeg_val)\n","\n","\n","    noise_EEG_val = np.array(noise_EEG_val)\n","    EEG_val = np.array(EEG_val)\n","\n","\n","    # std for noisy EEG\n","    EEG_val_end_standard = []\n","    noiseEEG_val_end_standard = []\n","    # std_VALUE = []\n","    for i in range(noise_EEG_val.shape[0]):\n","        \n","        # store std value to restore EEG signal\n","        std_value = np.std(noise_EEG_val[i])\n","        #std_VALUE.append(std_value)\n","\n","        # Each epochs of eeg and neeg was divide by the standard deviation\n","        eeg_val_all_std = EEG_val[i] / std_value\n","        EEG_val_end_standard.append(eeg_val_all_std)\n","\n","        noiseeeg_val_end_standard = noise_EEG_val[i] / std_value\n","        noiseEEG_val_end_standard.append(noiseeeg_val_end_standard)\n","\n","    #std_VALUE = np.array(std_VALUE)\n","    noiseEEG_val_end_standard = np.array(noiseEEG_val_end_standard)\n","    EEG_val_end_standard = np.array(EEG_val_end_standard)\n","    print('validation data prepared, validation data shape: ', noiseEEG_val_end_standard.shape, EEG_val_end_standard.shape)\n","\n","    #################################  simulate noise signal of test  ##############################\n","\n","    SNR_test_dB = np.linspace(-7.0, 2.0, num=(10))\n","    SNR_test = 10 ** (0.1 * (SNR_test_dB))\n","\n","    eeg_test = np.array(test_eeg)\n","    noise_test = np.array(test_noise)\n","    \n","    # combin eeg and noise for test set \n","    EEG_test = []\n","    noise_EEG_test = []\n","    for i in range(10):\n","        \n","        noise_eeg_test = []\n","        for j in range(eeg_test.shape[0]):\n","            eeg = eeg_test[j]\n","            noise = noise_test[j]\n","            \n","            coe = get_std(eeg) / (get_std(noise) * SNR_test[i])\n","            noise = noise * coe\n","            neeg = noise + eeg\n","            \n","            noise_eeg_test.append(neeg)\n","        \n","        EEG_test.extend(eeg_test)\n","        noise_EEG_test.extend(noise_eeg_test)\n","\n","\n","    noise_EEG_test = np.array(noise_EEG_test)\n","    EEG_test = np.array(EEG_test)\n","\n","\n","    # std for noisy EEG\n","    EEG_test_end_standard = []\n","    noiseEEG_test_end_standard = []\n","    std_VALUE = []\n","    for i in range(noise_EEG_test.shape[0]):\n","        \n","        # store std value to restore EEG signal\n","        std_value = np.std(noise_EEG_test[i])\n","        std_VALUE.append(std_value)\n","\n","        # Each epochs of eeg and neeg was divide by the standard deviation\n","        eeg_test_all_std = EEG_test[i] / std_value\n","        EEG_test_end_standard.append(eeg_test_all_std)\n","\n","        noiseeeg_test_end_standard = noise_EEG_test[i] / std_value\n","        noiseEEG_test_end_standard.append(noiseeeg_test_end_standard)\n","\n","    std_VALUE = np.array(std_VALUE)\n","    noiseEEG_test_end_standard = np.array(noiseEEG_test_end_standard)\n","    EEG_test_end_standard = np.array(EEG_test_end_standard)\n","    print('test data prepared, test data shape: ', noiseEEG_test_end_standard.shape, EEG_test_end_standard.shape)\n","\n","    return noiseEEG_train_end_standard, EEG_train_end_standard, noiseEEG_val_end_standard, EEG_val_end_standard, noiseEEG_test_end_standard, EEG_test_end_standard, std_VALUE"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Av2NxfrY3jYn"},"source":["<h2 style=\" font-size:150%; color:red ;\"> <b> 1.3 splitting in train, val, test</b> </h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T06:35:49.464353Z","iopub.status.busy":"2023-06-14T06:35:49.463962Z","iopub.status.idle":"2023-06-14T06:36:48.642350Z","shell.execute_reply":"2023-06-14T06:36:48.641241Z","shell.execute_reply.started":"2023-06-14T06:35:49.464318Z"},"executionInfo":{"elapsed":51468,"status":"ok","timestamp":1683190512802,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"daeq6y5z3lDB","outputId":"a72b106a-100e-49f8-fa3f-468618950d41","trusted":true},"outputs":[],"source":["#CREATING THE WHOLE TRAING VALIDATION AND TEST DATABASE\n","#for each pure EEg we are going to select 100 pure EMG and 100 pure EOG and obtained resulting raw data\n","#at the end we will have 4514*200 tuples o f(raw_eeg_train, clean_eeg_train, raw_eeg_val, clean_eeg_val, raw_eeg_test, clean_eeg_test)\n","train_dataset=[[],[]]\n","validation_dataset=[[],[]]\n","test_dataset=[[],[]]\n","\n","train_dataset_EMG=[[],[]]\n","validation_dataset_EMG=[[],[]]\n","test_dataset_EMG=[[],[]]\n","\n","train_dataset_EOG=[[],[]]\n","validation_dataset_EOG=[[],[]]\n","test_dataset_EOG=[[],[]]\n","\n","#for element in pure_EEG:\n","#combining the EEg with 100 random EMG\n","#for i in np.random.randint(0,len(pure_EMG),100):\n","noiseEEG_train, EEG_train, noiseEEG_val, EEG_val, noiseEEG_test, EEG_test, test_std_VALUE = prepare_data(EEG_all = pure_EEG, noise_all = pure_EMG, combin_num = 10, train_per = 0.8, noise_type = 'EMG')\n","train_dataset_EMG[0]=noiseEEG_train\n","train_dataset_EMG[1]=EEG_train\n","validation_dataset_EMG[0]=noiseEEG_val\n","validation_dataset_EMG[1]=EEG_val\n","test_dataset_EMG[0]=noiseEEG_test\n","test_dataset_EMG[1]=EEG_test\n","\n","#combining the EEG with 100 random EOG\n","#for i in np.random(0,len(pure_EOG),100):\n","noiseEEG_train, EEG_train, noiseEEG_val, EEG_val, noiseEEG_test, EEG_test, test_std_VALUE = prepare_data (EEG_all = pure_EEG, noise_all = pure_EOG, combin_num = 10, train_per = 0.8, noise_type = 'EOG')\n","train_dataset_EOG[0]=noiseEEG_train\n","train_dataset_EOG[1]=EEG_train\n","validation_dataset_EOG[0]=noiseEEG_val\n","validation_dataset_EOG[1]=EEG_val\n","test_dataset_EOG[0]=noiseEEG_test\n","test_dataset_EOG[1]=EEG_test\n","\n","#creating a mixed dataset\n","train_dataset[0]=np.vstack((train_dataset_EMG[0],train_dataset_EOG[0]))\n","train_dataset[1]=np.vstack((train_dataset_EMG[1],train_dataset_EOG[1]))\n","validation_dataset[0]=np.vstack((validation_dataset_EMG[0],validation_dataset_EOG[0]))\n","validation_dataset[1]=np.vstack((validation_dataset_EMG[1],validation_dataset_EOG[1]))\n","test_dataset[0]=np.vstack((test_dataset_EMG[0],test_dataset_EOG[0]))\n","test_dataset[1]=np.vstack((test_dataset_EMG[1],test_dataset_EOG[1]))\n","\n","#creating a datset divided only in train and test\n","train_dataset_only_EOG=[[],[]]\n","train_dataset_only_EMG=[[],[]]\n","train_dataset_only_EOG[0]=np.vstack((train_dataset_EOG[0],validation_dataset_EOG[0]))\n","train_dataset_only_EMG[1]=np.vstack((train_dataset_EMG[0],validation_dataset_EMG[0]))\n","print('the number of total (EMG and EOG noise added) training saples is',len(train_dataset[0]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2 style=\" font-size:180%; color:red; text-align:center;\"> <b> 2. METRICS AND LEARNING PARAMETERS </b> </h2>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2 style=\" font-size:150%; color:red;\"> <b> 2.1. metrics </b> </h2>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<div style=\"size 80%; \">Calculate the metrics as follows: \n","<ul>\n","    <li> <b>SNR</b>: Signal to Noise Ratio </li>\n","    <li> <b>PSNR</b>: Peak Signal to Noise Ratio </li>\n","    <li> <b>SSIM</b>: Structural Similarity Index </li>\n","    <li> <b>RMS></b>: Root Mean Square </li>\n","    <li> <b>RRMSE</b>: Relative Root Mean Square Error </li>\n","</ul>\n"," the formula for each metric is: \n","<ul>\n","    <li> <b>SNR</b>: 10 * log10((∑(x_i^2)) / (∑((x_i - x̂_i)^2))) </li>\n","    <li> <b>PSNR</b>: 10 * log10((MAX^2) / MSE) </li>\n","    <li> <b>SSIM</b>:  [(2μ_xμ_x̂ + c_1)(2σ_{x x̂} + c_2)] / [(μ_x^2 + μ_x̂^2 + c_1)(σ_x^2 + σ_x̂^2 + c_2)] </li>\n","    <li> <b>RMS</b>: sqrt((1/N) * ∑((x_i - x̂_i)^2)) </li>\n","    <li> <b>RRMSE</b>: RMS(x-x̂) / RMS(x) </li>\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T06:36:48.645037Z","iopub.status.busy":"2023-06-14T06:36:48.643822Z","iopub.status.idle":"2023-06-14T06:36:48.657057Z","shell.execute_reply":"2023-06-14T06:36:48.655759Z","shell.execute_reply.started":"2023-06-14T06:36:48.644999Z"},"trusted":true},"outputs":[],"source":["#CALCULATE RRMSE, PSNR, SSIM\n","def RMS(x):\n","        len=np.shape(x)[1]\n","        sum_=np.sum(x**2,axis=1)\n","        return np.sqrt(sum_/len)\n","def metrics_results(denoised, clear):\n","    #calculate the RRMSE\n","    max_clear=np.max(clear,axis=1)\n","  \n","    print('RMS of the clear signal is',RMS(clear))\n","    print('RMS of the clear minus denoised signal is',RMS(clear-denoised))\n","    #calculate the RRMSE\n","    #subtract the denoised from the clear\n","    sub=np.subtract(clear,denoised)\n","    RRMSE_values = RMS(sub)/RMS(clear)\n","    print('RRMSE values are',RRMSE_values)\n","    RRMSE=np.mean(RRMSE_values)\n","\n","    #calculate the CC\n","    CC_values = np.zeros((denoised.shape[0],1))\n","    for i in range(denoised.shape[0]):\n","        CC_values[i] = np.corrcoef(np.array(denoised[i,:]),np.array(clear[i,:]))[0,1]\n","    CC=np.mean(CC_values)\n","\n","    #calculate the PSNR\n","    mse_values=np.mean((denoised- clear)**2, axis=1)\n","    PSNR_values = 10 * np.log10(max_clear**2/mse_values)\n","    PSNR=np.mean(PSNR_values)\n","\n","\n","    from skimage.metrics import structural_similarity as ssim\n","    #calculate the SSIM\n","    SSIM_values = np.zeros((denoised.shape[0],1))\n","    for i in range(denoised.shape[0]):\n","        SSIM_values[i] = ssim(np.array(denoised[i,:]),np.array(clear[i,:]),data_range=max_clear[i])\n","    SSIM=np.mean(SSIM_values)\n","    \n","    return RRMSE, CC, PSNR, SSIM"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2 style=\" font-size:150%; color:red;\"> <b> 2.2 loss function and optimizer </b> </h2>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<div> The loss function used is the <b> Mean Squared Error </b> and the optimizer is <b> Adam </b> with a learning rate of <b> 0.001 </b> </div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T06:36:48.659478Z","iopub.status.busy":"2023-06-14T06:36:48.658592Z","iopub.status.idle":"2023-06-14T06:36:48.673106Z","shell.execute_reply":"2023-06-14T06:36:48.672199Z","shell.execute_reply.started":"2023-06-14T06:36:48.659397Z"},"trusted":true},"outputs":[],"source":["import time \n","#loss function\n","def loss_function(y_true, y_pred):\n","    loss = tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n","    return loss\n","\n","#optimizer\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2 style=\" font-size:150%; color:red;\"> <b> 2.3 training function </b> </h2>\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<div> the training function takes as input:\n","    <ul> \n","        <li> <b> model </b>: the model to be trained </li>\n","        <li> <b> dataset </b>: the dataset containing the training data </li>\n","        <li> <b> val_dataset </b>: the dataset containing the validation data </li>\n","        <li> <b> noise_type </b>: the type of noise we are denoising from between 'EOG' and 'EMG' </li>\n","        <li> <b> model_name </b>: the name of the model </li>\n","        <li> <b> results_path </b>: the path where the results are saved </li>\n","        <li> <b> epochs </b>: the number of epochs </li>\n","        <li> <b> batch_size </b>: the batch size </li>\n","    </ul>\n","\n","</div>\n","<div style=\"color:red\" > <b> Note:</b> </div> <div> this function <b> always </b> saves the model. </div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T06:36:48.677877Z","iopub.status.busy":"2023-06-14T06:36:48.677421Z","iopub.status.idle":"2023-06-14T06:36:48.689405Z","shell.execute_reply":"2023-06-14T06:36:48.688336Z","shell.execute_reply.started":"2023-06-14T06:36:48.677845Z"},"trusted":true},"outputs":[],"source":["def train_model(model, dataset, val_dataset, noise_type, model_name, results_path, epochs=60, batch_size=1):\n","    input = np.reshape(dataset[0],(len(dataset[0]),1,512))\n","    target = np.reshape(dataset[1],(len(dataset[1]),1,512))\n","    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n","\n","    #reshape validation data\n","    val_input= np.reshape(val_dataset[0],(len(val_dataset[0]),1,512))\n","    val_target= np.reshape(val_dataset[1],(len(val_dataset[1]),1,512))\n","    trained_model=model.fit((input, input), target, batch_size, epochs,  verbose=1, validation_data=((val_input, val_input), val_target))\n","\n","    #save the trained model\n","    model.save_weights(os.path.join(results_path, model_name, noise_type,'model'))\n","    #save the history (create the file if it doesn't exist)\n","    if not os.path.exists(os.path.join(results_path, model_name, noise_type, 'history.csv')):\n","        with open(os.path.join(results_path, model_name, noise_type, 'history.csv'), 'w') as f:\n","            f.write('loss,accuracy,val_loss,val_accuracy\\n')\n","    #save the history\n","    with open(os.path.join(results_path, model_name, noise_type, 'history.csv'), 'a') as f:\n","        for i in range(len(trained_model.history['loss'])):\n","            f.write(str(trained_model.history['loss'][i])+','+str(trained_model.history['accuracy'][i])+','+str(trained_model.history['val_loss'][i])+','+str(trained_model.history['val_accuracy'][i])+'\\n')\n","\n","    #return the trained model\n","    return trained_model\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h1 style=\" font-size:180%; color:red; text-align:center;\"> <b> 3. PROPOSED MODEL </b> </h1>"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HaOL6SX_-DYH"},"source":["<h2 style=\" font-size:150%; color:red;\"> <b> 3.1 importing layers</b> </h2>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T07:14:05.321890Z","iopub.status.busy":"2023-06-14T07:14:05.321505Z","iopub.status.idle":"2023-06-14T07:14:05.330093Z","shell.execute_reply":"2023-06-14T07:14:05.328037Z","shell.execute_reply.started":"2023-06-14T07:14:05.321859Z"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1683190512803,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"j3mmLz-p-Iw2","trusted":true},"outputs":[],"source":["\n","from tensorflow.keras.layers import LayerNormalization, Layer, Dense, ReLU, Dropout, MultiHeadAttention, Embedding, BatchNormalization, Conv1D"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T08:40:16.273838Z","iopub.status.busy":"2023-06-14T08:40:16.273433Z","iopub.status.idle":"2023-06-14T08:40:16.289423Z","shell.execute_reply":"2023-06-14T08:40:16.288245Z","shell.execute_reply.started":"2023-06-14T08:40:16.273806Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras import Sequential\n","class Res_BasicBlock(layers.Layer):\n","  def __init__(self,kernelsize, stride=1):\n","    super(Res_BasicBlock, self).__init__()\n","    self.bblock = Sequential([layers.Conv1D(32,kernelsize,strides=stride,padding=\"same\"),\n","                              layers.BatchNormalization(),\n","                              layers.ReLU(),\n","                              layers.Conv1D(16,kernelsize,strides=1,padding=\"same\"),\n","                              layers.BatchNormalization(),\n","                              layers.ReLU(),\n","                              layers.Conv1D(512,kernelsize,strides=1,padding=\"same\"),\n","                              layers.BatchNormalization(),\n","                              layers.ReLU()])\n","                              \n","    self.jump_layer = lambda x:x\n","\n","\n","  def call(self, inputs, training=None):\n","    #Through the convolutional layer\n","    out = self.bblock(inputs)\n","    #skip\n","    identity = self.jump_layer(inputs)\n","\n","    output = layers.add([out, identity])  #layers下面有一个add，把这2个层添加进来相加。\n","    \n","    return output\n","\n","\n","class BasicBlockall(layers.Layer):\n","  def __init__(self, stride=1):\n","    super(BasicBlockall, self).__init__()\n","\n","    self.bblock3 = Sequential([Res_BasicBlock(3),\n","                              Res_BasicBlock(3)\n","                              ])                      \n","    \n","    self.bblock5 = Sequential([Res_BasicBlock(5),\n","                              Res_BasicBlock(5)\n","                              ])                      \n","\n","    self.bblock7 = Sequential([Res_BasicBlock(7),\n","                              Res_BasicBlock(7)\n","                              ])\n","                              \n","    self.downsample = lambda x:x\n","\n","\n","  def call(self, inputs, training=None):\n"," \n","    out3 = self.bblock3(inputs)\n","    out5 = self.bblock5(out3)\n","    out7 = self.bblock7(out5)\n","\n","    \n","    return out7"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2 style=\" font-size:150%; color:red;\"> <b> 3.2 encoder and decoder architecture </b> </h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T08:40:19.669900Z","iopub.status.busy":"2023-06-14T08:40:19.669502Z","iopub.status.idle":"2023-06-14T08:40:22.748574Z","shell.execute_reply":"2023-06-14T08:40:22.747449Z","shell.execute_reply.started":"2023-06-14T08:40:19.669868Z"},"executionInfo":{"elapsed":4193,"status":"ok","timestamp":1683190516978,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"tXB47aQ99fYO","outputId":"485eb59f-9f06-4da4-bcfc-a0b8d691f0be","trusted":true},"outputs":[],"source":["#CRETING AN ENCODER\n","class Encoder(Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1, **kwargs):\n","        super(Encoder, self).__init__(**kwargs)\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.dff = dff\n","        self.rate = rate\n","        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n","        self.ffn = tf.keras.Sequential([\n","            Dense(dff, activation=\"relu\"),\n","            Dense(d_model),\n","        ])\n","        self.position_embedding = Embedding(input_dim=512, output_dim=1, input_length=512)\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","        self.basic_block = BasicBlockall()\n","    def call(self, inputs, training):\n","        #inputs embedding\n","        positions = tf.range(start=0, limit=512, delta=1)\n","        embedded_positions = self.position_embedding(positions)\n","        inputs = inputs + tf.squeeze(embedded_positions, axis=1)  # Remove the extra dimension\n","\n","        \n","        attn_output = self.mha(inputs, inputs) # self-attention\n","        attn_output = self.dropout1(attn_output, training=training)# dropout\n","        out1 = self.layernorm1(inputs + attn_output) # add and norm\n","        out2 = self.basic_block(out1)  # additional BasicBlockall layer\n","        ffn_output = self.ffn(out2) # point-wise feed forward\n","        ffn_output = self.dropout2(ffn_output, training=training) # dropout\n","        out3= self.layernorm2(out2 + ffn_output)   # add and norm\n","        \n","       \n","        return out3\n","\n"," \n","    def get_config(self):\n","        config = super(Encoder, self).get_config()\n","        config.update({\n","            'd_model': self.d_model,\n","            'num_heads': self.num_heads,\n","            'dff': self.dff,\n","            'rate': self.rate,\n","        })\n","        return config\n","\n","#Calling the encoder\n","encoder = Encoder(d_model=512, num_heads=8, dff=512, rate=0.1)\n","\n","#reshaping train_dataset_EOG[0] into batch_size, input_seq_len, d_model\n","train_dataset_EOG[0]=np.reshape(train_dataset_EOG[0],(len(train_dataset_EOG[0]),1,512))\n","\n","#executing the encoder\n","sample_encoder_output = encoder(train_dataset_EOG[0], training=False)\n","print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)\n","\n","#CREATING A DECODER\n","class Decoder(Layer):\n","\n","    def __init__(self, d_model, num_heads, dff, rate=0.1, **kwargs):\n","        super(Decoder, self).__init__(**kwargs)\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.dff = dff\n","        self.rate = rate\n","        self.position_embedding = Embedding(input_dim=512, output_dim=1, input_length=512)\n","        self.mha1 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n","        self.mha2 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n","        self.ffn = tf.keras.Sequential([\n","            Dense(dff, activation=\"relu\"),\n","            Dense(d_model),\n","        ])\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","        self.dropout3 = Dropout(rate)\n","        self.basic_block = BasicBlockall()\n"," \n","    def call(self, inputs, encoder_outputs, training):\n","        #inputs embedding\n","        positions = tf.range(start=0, limit=512, delta=1)\n","        embedded_positions = self.position_embedding(positions)\n","        inputs = inputs + tf.squeeze(embedded_positions, axis=1)  # Remove the extra dimension\n","\n","        attn1 = self.mha1(inputs, inputs) # self-attention\n","        attn1 = self.dropout1(attn1, training=training) # dropout\n","        out1 = self.layernorm1(inputs + attn1) # add and norm\n"," \n","        attn2 = self.mha2(out1, encoder_outputs) # encoder-decoder attention\n","        attn2 = self.dropout2(attn2, training=training) # dropout\n","        out2 = self.layernorm2(out1 + attn2) # add and norm\n","        \n","        out3 = self.basic_block(out2)  # additional BasicBlockall layer\n","        \n","        ffn_output = self.ffn(out3) # point-wise feed forward\n","        ffn_output = self.dropout3(ffn_output, training=training) # dropout\n","        out4= self.layernorm3(out3 + ffn_output) # add and norm\n","        \n","        return out4\n"," \n","    def get_config(self):\n","        config = super(Decoder, self).get_config()\n","        config.update({\n","            'd_model': self.d_model,\n","            'num_heads': self.num_heads,\n","            'dff': self.dff,\n","            'rate': self.rate,\n","        })\n","        return config\n","decoder = Decoder(d_model=512, num_heads=8, dff=512, rate=0.1)\n","\n","sample_decoder_output = decoder(train_dataset_EOG[0],train_dataset_EOG[0], training=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2 style=\" font-size:150%; color:red;\"> <b> 3.3 transformer model </b> </h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T07:27:13.412957Z","iopub.status.busy":"2023-06-14T07:27:13.412563Z","iopub.status.idle":"2023-06-14T07:27:13.424294Z","shell.execute_reply":"2023-06-14T07:27:13.423144Z","shell.execute_reply.started":"2023-06-14T07:27:13.412924Z"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683190516978,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"bUZiJsNd9fYP","trusted":true},"outputs":[],"source":["#CREATING THE TRANSFORMER\n","class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n","                 target_vocab_size, rate=0.1, **kwargs):\n","        super(Transformer, self).__init__(**kwargs)\n","        self.num_layers=num_layers\n","        self.d_model=d_model\n","        self.d_model=d_model\n","        self.num_heads=num_heads\n","        self.dff=dff\n","        self.input_vocab_size=input_vocab_size\n","        self.target_vocab_size=target_vocab_size\n","        self.rate=rate\n","        #create  positional encoding layer\n","        self.encoder = Encoder(d_model, num_heads, dff, rate)\n","        self.decoder = Decoder(d_model, num_heads, dff, rate)\n","        self.final_layer = Dense(target_vocab_size)\n"," \n","    def call(self, inputs, training):\n","        inp, tar = inputs\n","        enc_output = self.encoder(inp, training)\n","        dec_output = self.decoder(tar, enc_output, training)\n","        final_output = self.final_layer(dec_output)\n","        return final_output\n","\n","    def get_config(self):\n","        config = super(Transformer, self).get_config()\n","        config.update({\n","            'num_layers': self.num_layers,\n","            'd_model': self.d_model,\n","            'num_heads': self.num_heads,\n","            'dff': self.dff,\n","            'input_vocab_size': self.input_vocab_size,\n","            'target_vocab_size': self.target_vocab_size,\n","            'rate': self.rate,\n","        })\n","        return config\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2 style=\" font-size:180%; color:red; text-align:center;\"> <b> 4. EXPERIMENTS </b> </h2>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2 style=\" font-size:150%; color:red;\"> <b> 4.1 EOG denoising </b> </h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T07:27:17.757096Z","iopub.status.busy":"2023-06-14T07:27:17.756694Z","iopub.status.idle":"2023-06-14T07:27:17.957395Z","shell.execute_reply":"2023-06-14T07:27:17.956402Z","shell.execute_reply.started":"2023-06-14T07:27:17.757065Z"},"executionInfo":{"elapsed":1455,"status":"ok","timestamp":1683190518418,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"8je4ehYt9fYP","trusted":true},"outputs":[],"source":["#building the transformer\n","model_EOG =Transformer(num_layers=2, d_model=512, num_heads=8, dff=512, input_vocab_size=512, target_vocab_size=512, rate=0.1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T07:27:20.615607Z","iopub.status.busy":"2023-06-14T07:27:20.615209Z","iopub.status.idle":"2023-06-14T07:27:22.039110Z","shell.execute_reply":"2023-06-14T07:27:22.037108Z","shell.execute_reply.started":"2023-06-14T07:27:20.615579Z"},"executionInfo":{"elapsed":4189318,"status":"ok","timestamp":1683196839278,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"EtTOW_P39fYR","outputId":"aa9546c9-0e69-436e-9cad-54423c99755f","trusted":true},"outputs":[],"source":["#TRAINING THE TRANSFORMER\n","#train the model\n","\n","trained_model_EOG = train_model(model_EOG, train_dataset_EOG, validation_dataset_EOG, 'EOG', model_name, results_path, epochs=60, batch_size=32)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<div> plot the loss of the model </div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-14T06:36:58.950609Z","iopub.status.idle":"2023-06-14T06:36:58.951509Z","shell.execute_reply":"2023-06-14T06:36:58.951255Z","shell.execute_reply.started":"2023-06-14T06:36:58.951228Z"},"trusted":true},"outputs":[],"source":["#read history csv\n","history_EOG = pd.read_csv(os.path.join(results_path, model_name, 'EOG', 'history.csv'))\n","#plot the loss\n","plt.plot(history_EOG['loss'])\n","plt.plot(history_EOG['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.savefig(os.path.join(results_path, model_name, 'EOG', 'loss.png'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-14T06:36:58.953633Z","iopub.status.idle":"2023-06-14T06:36:58.954553Z","shell.execute_reply":"2023-06-14T06:36:58.954300Z","shell.execute_reply.started":"2023-06-14T06:36:58.954273Z"},"trusted":true},"outputs":[],"source":["\n","#load the model\n","#load weights\n","model_EOG.load_weights(os.path.join(results_path, model_name, 'EOG', 'model'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-14T06:36:58.956121Z","iopub.status.idle":"2023-06-14T06:36:58.957026Z","shell.execute_reply":"2023-06-14T06:36:58.956756Z","shell.execute_reply.started":"2023-06-14T06:36:58.956728Z"},"executionInfo":{"elapsed":2169,"status":"ok","timestamp":1683197193056,"user":{"displayName":"martina doku","userId":"09886462720658549090"},"user_tz":-120},"id":"7fzW3hpkW5i_","outputId":"d7e93612-fcf0-4cf0-fd64-7c27063b6eba","trusted":true},"outputs":[],"source":["#import skimage\n","\n","#predict the test dataset\n","test_dataset_EOG[0]=np.reshape(test_dataset_EOG[0],(len(test_dataset_EOG[0]),1,512))\n","pred_EOG=model_EOG((test_dataset_EOG[0], test_dataset_EOG[0]), training=False)\n","\n","\n","#calculate the metrics\n","pred_EOG=np.reshape(pred_EOG,(len(pred_EOG),512))\n","test_dataset_EOG[1]=np.reshape(test_dataset_EOG[1],(len(test_dataset_EOG[1]),512))\n","\n","#print the two shapes\n","print('pred shape:',pred_EOG.shape)\n","print('test shape:',test_dataset_EOG[1].shape)\n","RRMSE, CC, PSNR, SSIM=metrics_results(pred_EOG, test_dataset_EOG[1])\n","print('RRMSE:',RRMSE,'CC:',CC,'PSNR:',PSNR,'SSIM',SSIM)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-14T06:36:58.958584Z","iopub.status.idle":"2023-06-14T06:36:58.959487Z","shell.execute_reply":"2023-06-14T06:36:58.959235Z","shell.execute_reply.started":"2023-06-14T06:36:58.959207Z"},"trusted":true},"outputs":[],"source":["#plot a semple result of the prediction vs the target\n","#plot a semple result of the prediction vs the target vs the input\n","#reshape the input\n","test_dataset_EOG[0]=np.reshape(test_dataset_EOG[0],(len(test_dataset_EOG[0]),512))\n","\n","plt.plot(test_dataset_EOG[0][0], label='input')\n","plt.plot(pred_EOG[0], label='prediction')\n","plt.plot(test_dataset_EOG[1][0], label='target')\n","\n","plt.legend()\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2 style=\" font-size:150%; color:red;\"> <b> 4.2 EMG denoising</b> </h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-14T06:36:58.961016Z","iopub.status.idle":"2023-06-14T06:36:58.961928Z","shell.execute_reply":"2023-06-14T06:36:58.961643Z","shell.execute_reply.started":"2023-06-14T06:36:58.961605Z"},"trusted":true},"outputs":[],"source":["#create the model\n","model_EMG =Transformer(num_layers=2, d_model=512, num_heads=8, dff=512, input_vocab_size=512, target_vocab_size=512, rate=0.1)\n","\n","#calling the train_transformer function\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-14T06:36:58.963479Z","iopub.status.idle":"2023-06-14T06:36:58.964371Z","shell.execute_reply":"2023-06-14T06:36:58.964104Z","shell.execute_reply.started":"2023-06-14T06:36:58.964076Z"},"trusted":true},"outputs":[],"source":["#TRAINING THE TRANSFORMER\n","#train the model\n","\n","trained_model_EMG = train_model(model_EMG, train_dataset_EMG, validation_dataset_EMG, 'EMG', model_name, results_path, epochs=40, batch_size=32)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h1> plot the history <h1>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-14T06:36:58.965904Z","iopub.status.idle":"2023-06-14T06:36:58.966766Z","shell.execute_reply":"2023-06-14T06:36:58.966515Z","shell.execute_reply.started":"2023-06-14T06:36:58.966489Z"},"trusted":true},"outputs":[],"source":["#read history csv\n","history_EMG = pd.read_csv(os.path.join(results_path, model_name, 'EMG', 'history.csv'))\n","#plot the loss\n","plt.plot(history_EMG['loss'])\n","plt.plot(history_EMG['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.savefig(os.path.join(results_path, model_name, 'EMG', 'loss.png'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-14T06:36:58.968330Z","iopub.status.idle":"2023-06-14T06:36:58.969219Z","shell.execute_reply":"2023-06-14T06:36:58.968941Z","shell.execute_reply.started":"2023-06-14T06:36:58.968913Z"},"trusted":true},"outputs":[],"source":["#load the model\n","model_EMG.load_weights(os.path.join(results_path,model_name,'EMG', 'model'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-14T06:36:58.970742Z","iopub.status.idle":"2023-06-14T06:36:58.971629Z","shell.execute_reply":"2023-06-14T06:36:58.971377Z","shell.execute_reply.started":"2023-06-14T06:36:58.971350Z"},"trusted":true},"outputs":[],"source":["#predict the test dataset\n","test_dataset_EMG[0]=np.reshape(test_dataset_EMG[0],(len(test_dataset_EMG[0]),1,512))\n","pred_EMG=model_EMG((test_dataset_EMG[0], test_dataset_EMG[0]), training=False)\n","#calculate the metrics\n","pred_EMG=np.reshape(pred_EMG,(len(pred_EMG),512))\n","test_dataset_EMG[1]=np.reshape(test_dataset_EMG[1],(len(test_dataset_EMG[1]),512))\n","RRMSE, CC, PSNR, SSIM=metrics_results(pred_EMG, test_dataset_EMG[1])\n","print('RRMSE:',RRMSE,'CC:',CC,'PSNR:',PSNR,'SSIM',SSIM)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-14T06:36:58.973197Z","iopub.status.idle":"2023-06-14T06:36:58.974056Z","shell.execute_reply":"2023-06-14T06:36:58.973791Z","shell.execute_reply.started":"2023-06-14T06:36:58.973765Z"},"trusted":true},"outputs":[],"source":["\n","#plot a semple result of the prediction vs the target\n","#plot a semple result of the prediction vs the target vs the input\n","#reshape the input\n","test_dataset_EMG[0]=np.reshape(test_dataset_EMG[0],(len(test_dataset_EMG[0]),512))\n","\n","plt.plot(test_dataset_EMG[0][0], label='input')\n","plt.plot(pred_EMG[0], label='prediction')\n","plt.plot(test_dataset_EMG[1][0], label='target')\n","\n","plt.legend()\n","plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
